{
 "cells": [
  {
   "cell_type": "code",
   "id": "7dbbb955b0da812f",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T08:34:15.387063Z",
     "start_time": "2025-06-15T08:34:05.115652Z"
    }
   },
   "source": [
    "#Name: Georgios Strouggis\n",
    "#AM: 5357\n",
    "#Kaggle Team: AI Slop Squad\n",
    "\n",
    "#Preprocessing\n",
    "import gensim.downloader as api\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import igraph as ig\n",
    "import random\n",
    "\n",
    "#Feature Extraction / Document-Term Matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "#Dimensional Reduction\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#Model Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "#Text Categorization and Evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Others\n",
    "import csv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T08:35:19.890030Z",
     "start_time": "2025-06-15T08:34:29.137752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Preprocessing for Abstracts and Authors .txt files\n",
    "word2vec = api.load(\"word2vec-google-news-300\") #Loads Word2Vec model\n",
    "stop_words = set(stopwords.words('english')) #Loads common stop words\n",
    "\n",
    "first_line_count = 1\n",
    "first_line = \"\"\n",
    "\n",
    "#Opens abstracts.txt and turns each line into a list of words\n",
    "abstracts = {}\n",
    "with (open('abstracts.txt', 'r', encoding='utf-8') as ab): \n",
    "    for line in ab:\n",
    "        if first_line_count == 1: \n",
    "            first_line = line\n",
    "            first_line_count = 0\n",
    "        paper_id, abstract = line.split('|--|') \n",
    "        abstract = abstract.lower() \n",
    "        abstract = re.sub(r'[^\\w\\s]', '', abstract) \n",
    "        abstract_tokens = abstract.split()\n",
    "        abstract_tokens = [word for word in abstract_tokens if word not in stop_words]\n",
    "        abstracts[int(paper_id)] = abstract_tokens\n",
    "\n",
    "print(\"Abstract before preprocessing:\")\n",
    "print(first_line) #Shows first line unchanged\n",
    "\n",
    "print(\"Same abstract after partial preprocessing\")\n",
    "print(abstracts[0]) #Shows first line after filtering stopwords\n",
    "\n",
    "#Provides a list of all the words and their frequency in the abstracts overall\n",
    "common_words = dict()\n",
    "for i in abstracts:\n",
    "    for j in range(len(abstracts[i])):\n",
    "        if common_words.get(abstracts[i][j]) is None:\n",
    "            common_words[abstracts[i][j]] = 1\n",
    "        else:\n",
    "            common_words[abstracts[i][j]] += 1\n",
    "\n",
    "#Stores list of top 500 most commonly used words from most to least used\n",
    "top_words = set(sorted(common_words, key=common_words.get, reverse=True)[:500])\n",
    "\n",
    "#Trims abstracts of top 500 most common words\n",
    "for paper_id in abstracts:\n",
    "    abstracts[paper_id] = [word for word in abstracts[paper_id] if word not in top_words]\n",
    "  \n",
    "print(\"\\nSame abstract after full preprocessing:\")\n",
    "print(abstracts[0]) #Shows first line after filtering the top 500 most common words\n",
    "\n",
    "first_line_count = 1\n",
    "first_line = \"\"\n",
    "\n",
    "#Opens authors.txt and turns each line into a list of words\n",
    "authors = {}\n",
    "with open('authors.txt', 'r', encoding='utf-8') as au:\n",
    "    for line in au:\n",
    "        if first_line_count == 1: \n",
    "            first_line = line\n",
    "            first_line_count = 0\n",
    "        paper_id, author = line.split('|--|')\n",
    "        author = author.strip()\n",
    "        author = author.split(',')\n",
    "        authors[int(paper_id)] = author\n",
    "\n",
    "print(\"\\nAbstract's authors before preprocessing:\")\n",
    "print(first_line) #Shows first line unchanged\n",
    "print(\"Abstract's authors after preprocessing:\")\n",
    "print(authors[0])"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract before preprocessing:\n",
      "0|--|The development of an automated system for the quality assessment of aerodrome ground lighting (AGL), in accordance with associated standards and recommendations, is presented. The system is composed of an image sensor, placed inside the cockpit of an aircraft to record images of the AGL during a normal descent to an aerodrome. A model-based methodology is used to ascertain the optimum match between a template of the AGL and the actual image data in order to calculate the position and orientation of the camera at the instant the image was acquired. The camera position and orientation data are used along with the pixel grey level for each imaged luminaire, to estimate a value for the luminous intensity of a given luminaire. This can then be compared with the expected brightness for that luminaire to ensure it is operating to the required standards. As such, a metric for the quality of the AGL pattern is determined. Experiments on real image data is presented to demonstrate the application and effectiveness of the system.\n",
      "\n",
      "Same abstract after partial preprocessing\n",
      "['development', 'automated', 'system', 'quality', 'assessment', 'aerodrome', 'ground', 'lighting', 'agl', 'accordance', 'associated', 'standards', 'recommendations', 'presented', 'system', 'composed', 'image', 'sensor', 'placed', 'inside', 'cockpit', 'aircraft', 'record', 'images', 'agl', 'normal', 'descent', 'aerodrome', 'modelbased', 'methodology', 'used', 'ascertain', 'optimum', 'match', 'template', 'agl', 'actual', 'image', 'data', 'order', 'calculate', 'position', 'orientation', 'camera', 'instant', 'image', 'acquired', 'camera', 'position', 'orientation', 'data', 'used', 'along', 'pixel', 'grey', 'level', 'imaged', 'luminaire', 'estimate', 'value', 'luminous', 'intensity', 'given', 'luminaire', 'compared', 'expected', 'brightness', 'luminaire', 'ensure', 'operating', 'required', 'standards', 'metric', 'quality', 'agl', 'pattern', 'determined', 'experiments', 'real', 'image', 'data', 'presented', 'demonstrate', 'application', 'effectiveness', 'system']\n",
      "\n",
      "Same abstract after full preprocessing:\n",
      "['development', 'automated', 'assessment', 'aerodrome', 'ground', 'lighting', 'agl', 'accordance', 'standards', 'recommendations', 'composed', 'sensor', 'placed', 'inside', 'cockpit', 'aircraft', 'record', 'agl', 'normal', 'descent', 'aerodrome', 'modelbased', 'methodology', 'ascertain', 'optimum', 'match', 'template', 'agl', 'actual', 'calculate', 'position', 'orientation', 'instant', 'acquired', 'position', 'orientation', 'along', 'pixel', 'grey', 'imaged', 'luminaire', 'luminous', 'intensity', 'luminaire', 'expected', 'brightness', 'luminaire', 'ensure', 'operating', 'required', 'standards', 'agl', 'determined']\n",
      "\n",
      "Abstract's authors before preprocessing:\n",
      "0|--|James H. Niblock,Jian-Xun Peng,Karen R. McMenemy,George W. Irwin\n",
      "\n",
      "Abstract's authors after preprocessing:\n",
      "['James H. Niblock', 'Jian-Xun Peng', 'Karen R. McMenemy', 'George W. Irwin']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T08:35:24.100119Z",
     "start_time": "2025-06-15T08:35:21.239094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Preprocessing for Edgelist\n",
    "g = ig.Graph(directed=False) #Creates undirected iGraph\n",
    "\n",
    "#Opens edgelist.txt and stores nodes from it\n",
    "nodes = []\n",
    "with open('edgelist.txt', 'r', encoding='utf-8') as ed:\n",
    "    for line in ed:\n",
    "        node1, node2 = line.strip().split(',')\n",
    "        nodes.append((node1, node2))\n",
    " \n",
    "#1000 randomly selected nodes that will later be used as positive training examples\n",
    "edge_set = set()\n",
    "set_count = 1000\n",
    "used_random_values = []\n",
    "while set_count > 0:\n",
    "    new_random = random.randint(0,len(nodes)-1)\n",
    "    if new_random not in used_random_values:\n",
    "        edge_set.add((nodes[new_random][0],nodes[new_random][1]))\n",
    "        used_random_values.append(new_random)\n",
    "        set_count -= 1\n",
    "        \n",
    "g.add_vertices(list(set([v for e in nodes for v in e]))) #Adds the nodes to the graph\n",
    "g.add_edges(nodes) #Adds edges connecting the nodes to the graph\n",
    "\n",
    "print(\"Number of vertices:\", g.vcount())\n",
    "print(\"Number of edges:\", g.ecount())"
   ],
   "id": "c547334080b5effa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices: 138499\n",
      "Number of edges: 1091955\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T08:35:28.341186Z",
     "start_time": "2025-06-15T08:35:27.841294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Feature Extraction\n",
    "#Computes average Word2Vec embedding for a list of tokens\n",
    "def get_sentence_embedding(tokens):\n",
    "    vectors = [word2vec[word] for word in tokens if word in word2vec]\n",
    "    if not vectors:\n",
    "        return np.zeros((1, word2vec.vector_size))\n",
    "    return np.mean(vectors, axis=0).reshape(1, -1)\n",
    "\n",
    "#Computes cosine similarity between the word2vec embeddings of two abstracts\n",
    "def sentence_embedding_similarity(t1,t2):\n",
    "    id1 = get_sentence_embedding(abstracts[t1])\n",
    "    id2 = get_sentence_embedding(abstracts[t2])\n",
    "    return round(cosine_similarity(id1,id2)[0][0],4)\n",
    "\n",
    "#Computes jaccard similarity between two lists of authors\n",
    "def jaccard_similarity(t1, t2):\n",
    "    union = len(list(set(t1) | set(t2)))\n",
    "    intersection = len(list(set(t1) & set(t2)))\n",
    "    return round(intersection/union,2)\n",
    "\n",
    "#Counts number of common neighbours between two nodes\n",
    "def common_neighbours(t1,t2):\n",
    "    neighbors1 = g.neighbors(t1)\n",
    "    neighbor_names1 = [g.vs[n]['name'] for n in neighbors1]\n",
    "    neighbors2 = g.neighbors(t2)\n",
    "    neighbor_names2 = [g.vs[n]['name'] for n in neighbors2]\n",
    "    return len(list(set(neighbor_names1) & set(neighbor_names2)))\n",
    "\n",
    "#Computes average degree centrality for two nodes\n",
    "def degree_centrality(t1,t2):\n",
    "    id1 = g.degree(str(t1)) / (g.vcount() - 1)\n",
    "    id2 = g.degree(str(t2)) / (g.vcount() - 1)\n",
    "    return round(((id1 + id2) / 2),4)\n",
    "\n",
    "#Computes keyword overlap ratio between two abstracts\n",
    "def keyword_overlap_ratio(t1,t2):\n",
    "    id1 = abstracts[t1]\n",
    "    id2 = abstracts[t2]\n",
    "    union = len(list(set(id1) | set(id2)))\n",
    "    intersection = len(list(set(id1) & set(id2)))\n",
    "    if union != 0:\n",
    "        return round(intersection/union,4)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Creates list of pagerank scores for all nodes\n",
    "pageranks = g.pagerank()\n",
    "pagerank_dict = {v[\"name\"]: pageranks[v.index] for v in g.vs}\n",
    "\n",
    "#Computes absolute difference in pagepank scores between two nodes\n",
    "def pagerank_difference(t1,t2):\n",
    "    id1 = pagerank_dict.get(str(t1), 0)\n",
    "    id2 = pagerank_dict.get(str(t2), 0)\n",
    "    return round(abs(id1 - id2),4)"
   ],
   "id": "e61b98e267995efd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T08:40:01.756660Z",
     "start_time": "2025-06-15T08:35:32.894385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Document-Term Matrix\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "set_of_abstracts = {id: ' '.join(tokens) for id, tokens in abstracts.items()} #Set of abstracts fused back into sentences\n",
    "sorted_set = [set_of_abstracts[id] for id in sorted(set_of_abstracts)] #The above set sorted\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sorted_set) #Matrix for the frequency of each word in each abstract\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10) #\"Finds\" the topics of the abstract\n",
    "topic_features = lda.fit_transform(tfidf_matrix)\n",
    "\n",
    "#Dimensional Reduction\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "tfidf_matrix = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "#Sorted list of papers by ids\n",
    "indexes = {index: id for id, index in enumerate(sorted(set_of_abstracts))}\n",
    "\n",
    "#Computes cosine similarity between papers using tfidf matrix\n",
    "def tfidf_similarity(t1, t2):\n",
    "    id1 = tfidf_matrix[indexes[t1]]\n",
    "    id2 = tfidf_matrix[indexes[t2]]\n",
    "    tfidf_sim = cosine_similarity(id1.reshape(1, -1), id2.reshape(1, -1))[0][0]\n",
    "    return tfidf_sim\n",
    "  \n",
    "#Computes cosine similarity between papers using topics\n",
    "def lda_similarity(t1, t2):\n",
    "    id1 = topic_features[indexes[t1]]\n",
    "    id2 = topic_features[indexes[t2]]\n",
    "    lda_sim = cosine_similarity(id1.reshape(1, -1), id2.reshape(1, -1))[0][0]\n",
    "    return lda_sim\n",
    "\n",
    "#Computes all features for two papers\n",
    "def create_feature_matrix(id1, id2):\n",
    "    sim1 = sentence_embedding_similarity(id1,id2)\n",
    "    sim2 = jaccard_similarity(authors[id1], authors[id2])\n",
    "    cn = common_neighbours(str(id1), str(id2))\n",
    "    dc = degree_centrality(id1,id2)\n",
    "    kor = keyword_overlap_ratio(id1, id2)\n",
    "    pad = pagerank_difference(id1,id2)\n",
    "    tfidf_sim = tfidf_similarity(id1,id2)\n",
    "    lda_sim = lda_similarity(id1,id2)\n",
    "\n",
    "    return [sim1, sim2, cn, dc, kor, pad, tfidf_sim, lda_sim]"
   ],
   "id": "5d3d55cdf62da54b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T08:40:38.046946Z",
     "start_time": "2025-06-15T08:40:30.595731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Creates testing data\n",
    "positive_pairs = list(edge_set)\n",
    "random.shuffle(positive_pairs)\n",
    "pairs_num = len(positive_pairs)\n",
    "negative_pairs = []\n",
    "\n",
    "#Finds 1000 edges that are known negatives by virtue of not being in the known positives\n",
    "while pairs_num > 0:\n",
    "    r1 = random.randint(0,len(abstracts)-1)\n",
    "    r2 = random.randint(0,len(abstracts)-1)\n",
    "    if (str(r1), str(r2)) not in edge_set and (str(r2), str(r1)) not in edge_set:\n",
    "        negative_pairs.append((r1, r2))\n",
    "        pairs_num -= 1\n",
    "\n",
    "#Mixes positives and negatives together\n",
    "labeled_data = [(a, b, 1) for a, b in positive_pairs] + [(a, b, 0) for a, b in negative_pairs]\n",
    "random.shuffle(labeled_data)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "#Creates lists of mixed positive and negative examples as well as their labels respectively\n",
    "for a, b, label in labeled_data:\n",
    "    features = create_feature_matrix(int(a),int(b))\n",
    "    x.append(features)\n",
    "    y.append(label)"
   ],
   "id": "84865fa529f2c3c7",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T08:43:50.949127Z",
     "start_time": "2025-06-15T08:40:41.906053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model Learning, Text Categorization and Evaluation\n",
    "#Creates list of edges to be tested\n",
    "test = []\n",
    "with open('test.txt', 'r', encoding='utf-8') as t:\n",
    "    for line in t:\n",
    "        t1, t2 = map(int,line.strip().split(','))\n",
    "        test.append((t1, t2))\n",
    "\n",
    "x_test = [create_feature_matrix(id1, id2) for id1, id2 in test]\n",
    "\n",
    "#Standardizes the training and testing data for better results\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "#Random Forest (uses original data because tree-based algorithms don't need scaling)\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)\n",
    "scores = cross_val_score(rfc, x, y, cv=5, scoring='f1')\n",
    "logloss = cross_val_score(rfc, x, y, cv=5, scoring='neg_log_loss')\n",
    "rfc.fit(x,y)\n",
    "cal_rfc = CalibratedClassifierCV(rfc, method='isotonic', cv=5) #Calibrates classifier to improve prediction accuracy\n",
    "cal_rfc.fit(x, y)\n",
    "probs_rfc = cal_rfc.predict_proba(x_test)[:, 1] #Predict connection between test nodes\n",
    "\n",
    "print(\"Cross-validated F1 scores for Random Forest:\", scores)\n",
    "print(\"Mean F1 score for Random Forest:\", np.mean(scores))\n",
    "print(\"Cross-validated logloss for Random Forest:\", -logloss.mean())\n",
    "\n",
    "#Logistic Regression\n",
    "lr = LogisticRegressionCV(cv=5, max_iter=100, class_weight='balanced')\n",
    "scores = cross_val_score(lr, x_scaled, y, cv=5, scoring='f1')\n",
    "logloss = cross_val_score(lr, x_scaled, y, cv=5, scoring='neg_log_loss')\n",
    "lr.fit(x_scaled,y)\n",
    "cal_lr = CalibratedClassifierCV(lr, method='isotonic', cv=5)\n",
    "cal_lr.fit(x_scaled, y)\n",
    "probs_lr = cal_lr.predict_proba(x_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nCross-validated F1 scores for Logistic Regression:\", scores)\n",
    "print(\"Mean F1 score for Logistic Regression:\", np.mean(scores))\n",
    "print(\"Cross-validated logloss for Logistic Regression:\", -logloss.mean())\n",
    "\n",
    "\n",
    "#SVC\n",
    "svc = SVC(probability=True, kernel='linear', class_weight='balanced')\n",
    "scores = cross_val_score(svc, x_scaled, y, cv=5, scoring='f1')\n",
    "logloss = cross_val_score(svc, x_scaled, y, cv=5, scoring='neg_log_loss')\n",
    "svc.fit(x_scaled,y)\n",
    "cal_svc = CalibratedClassifierCV(svc, method='isotonic', cv=5)\n",
    "cal_svc.fit(x_scaled, y)\n",
    "probs_svc = cal_svc.predict_proba(x_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nCross-validated F1 scores for SVC:\", scores)\n",
    "print(\"Mean F1 score for SVC:\", np.mean(scores))\n",
    "print(\"Cross-validated logloss for SVC:\", -logloss.mean())\n",
    "\n",
    "#Gradient Boosting (uses original data because tree-based algorithms don't need scaling)\n",
    "gb = GradientBoostingClassifier(n_estimators=300, learning_rate=0.05, max_depth=3)\n",
    "scores = cross_val_score(gb, x, y, cv=5, scoring='f1')\n",
    "logloss = cross_val_score(gb, x, y, cv=5, scoring='neg_log_loss')\n",
    "gb.fit(x,y)\n",
    "cal_gb = CalibratedClassifierCV(gb, method='isotonic', cv=5)\n",
    "cal_gb.fit(x, y)\n",
    "probs_gb = cal_gb.predict_proba(x_test)[:, 1]\n",
    "\n",
    "print(\"\\nCross-validated F1 scores for Gradient Boosting:\", scores)\n",
    "print(\"Mean F1 score for Gradient Boosting:\", np.mean(scores))\n",
    "print(\"Cross-validated logloss for Gradient Boosting:\", -logloss.mean())\n",
    "\n",
    "#K Neighbours\n",
    "kn = KNeighborsClassifier(n_neighbors=40)\n",
    "scores = cross_val_score(kn, x_scaled, y, cv=5, scoring='f1')\n",
    "logloss = cross_val_score(kn, x_scaled, y, cv=5, scoring='neg_log_loss')\n",
    "kn.fit(x_scaled,y)\n",
    "cal_kn = CalibratedClassifierCV(kn, method='isotonic', cv=5)\n",
    "cal_kn.fit(x_scaled, y)\n",
    "probs_kn = cal_kn.predict_proba(x_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nCross-validated F1 scores for K Neighbours:\", scores)\n",
    "print(\"Mean F1 score for K Neighbours:\", np.mean(scores))\n",
    "print(\"Cross-validated logloss for K Neighbours:\", -logloss.mean())"
   ],
   "id": "6dc6c0c4e85641e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated F1 scores for Random Forest: [0.96163683 0.93877551 0.94416244 0.94710327 0.93233083]\n",
      "Mean F1 score for Random Forest: 0.9448017754047339\n",
      "Cross-validated logloss for Random Forest: 0.1505906586287944\n",
      "\n",
      "Cross-validated F1 scores for Logistic Regression: [0.95336788 0.93638677 0.93298969 0.95165394 0.92544987]\n",
      "Mean F1 score for Logistic Regression: 0.9399696300605613\n",
      "Cross-validated logloss for Logistic Regression: 0.15996551771434303\n",
      "\n",
      "Cross-validated F1 scores for SVC: [0.95064935 0.94117647 0.94601542 0.93877551 0.92783505]\n",
      "Mean F1 score for SVC: 0.9408903614305167\n",
      "Cross-validated logloss for SVC: 0.16981389142514183\n",
      "\n",
      "Cross-validated F1 scores for Gradient Boosting: [0.956743   0.93670886 0.94147583 0.93401015 0.93401015]\n",
      "Mean F1 score for Gradient Boosting: 0.9405895989689123\n",
      "Cross-validated logloss for Gradient Boosting: 0.15644277582322505\n",
      "\n",
      "Cross-validated F1 scores for K Neighbours: [0.89071038 0.91906005 0.89304813 0.89528796 0.87978142]\n",
      "Mean F1 score for K Neighbours: 0.8955775883910878\n",
      "Cross-validated logloss for K Neighbours: 0.3152916226467354\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T08:50:05.181985Z",
     "start_time": "2025-06-15T08:50:04.976812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Write submission file\n",
    "with open(\"submission.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"ID\", \"Label\"])\n",
    "    for id, prob in enumerate(probs_rfc):\n",
    "    #for id, prob in enumerate(probs_lr):\n",
    "    #for id, prob in enumerate(probs_svc):\n",
    "    #for id, prob in enumerate(probs_gb):\n",
    "    #for id, prob in enumerate(probs_kn):\n",
    "        writer.writerow([id, prob])"
   ],
   "id": "3da0cbecd16a4551",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T08:50:32.302081Z",
     "start_time": "2025-06-15T08:50:32.277092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Additional code implemented to compute feature importance, helped with fine tuning the model to prevent overfitting\n",
    "feature_names = [\n",
    "    \"sim1\", \"sim2\", \"common_neighbors\", \"degree_centrality\", \"keyword_overlap\", \"pagerank_diff\", \"tfidf_sim\", \"lda_sim\"]\n",
    "importances = rfc.feature_importances_\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for name, score in zip(feature_names, importances):\n",
    "    print(f\"{name}: {score:.4f}\")"
   ],
   "id": "d1da7c54b790942c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "sim1: 0.0643\n",
      "sim2: 0.0093\n",
      "common_neighbors: 0.4001\n",
      "degree_centrality: 0.1359\n",
      "keyword_overlap: 0.1089\n",
      "pagerank_diff: 0.0340\n",
      "tfidf_sim: 0.1559\n",
      "lda_sim: 0.0916\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
